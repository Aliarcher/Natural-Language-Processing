{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "from keras.layers import GRU, SimpleRNN\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "import gc\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = ['B-pers','I-pers', 'B-pro', 'I-pro','B-loc','I-loc','B-fac','I-fac','B-event','I-event','B-org','I-org','O']\n",
    "list_columns = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_one_hot(value):\n",
    "  list_classes = ['B-pers','I-pers', 'B-pro', 'I-pro','B-loc','I-loc','B-fac','I-fac','B-event','I-event','B-org','I-org','O']\n",
    "  if value == list_classes[0]:\n",
    "    return [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[1]:\n",
    "    return [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[2]:\n",
    "    return [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[3]:\n",
    "    return [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[4]:\n",
    "    return [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[5]:\n",
    "    return [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[6]:\n",
    "    return [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[7]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "  if value == list_classes[8]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "  if value == list_classes[9]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "  if value == list_classes[10]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
    "  if value == list_classes[11]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "  if value == list_classes[12]:\n",
    "    return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    df= pd.DataFrame(columns=list_columns)\n",
    "    \n",
    "    f = open(filename, encoding=\"utf8\")\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "            continue\n",
    "        splits = line.split(' ')        \n",
    "        sentence.append([splits[0], splits[-1]])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "        sentence = []\n",
    "        \n",
    "    for sentence in sentences:\n",
    "      text=''\n",
    "      words=[]\n",
    "      values=[]\n",
    "      for item in sentence:\n",
    "        words.append(item[0])\n",
    "        values.append(item[1].replace('\\n',''))\n",
    "      _list=[]\n",
    "      _list.append(' '.join(words))\n",
    "      _list.append(' '.join(values))\n",
    "      df2 = pd.DataFrame([_list], columns=list_columns)\n",
    "      df=df.append(df2, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['label']\n",
    "list_sentences_train = train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 250015\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "\n",
    "y = [[label_to_one_hot(c) for c in ey.split(' ')] for ey in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,120,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 60\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y_t = pad_sequences(y, maxlen=maxlen)\n",
    "print(len(X_t[0]))\n",
    "print(len(y_t[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Bidirectional Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(len(tokenizer.word_index), embedding_matrix.shape[1],weights=[embedding_matrix],trainable=False))\n",
    "model2.add(Bidirectional(LSTM(30, return_sequences=True,name='lstm')))\n",
    "model2.add(Bidirectional(LSTM(30, return_sequences=True,name='lstm')))\n",
    "model2.add(Dense(13, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer=\"rmsprop\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Model\n",
    "plt.style.use(\"ggplot\")\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PER-NER-BILSTM.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
